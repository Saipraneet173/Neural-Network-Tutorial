{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2829f17-607a-4ca8-b70c-1e08b5e6ffd0",
   "metadata": {},
   "source": [
    "# Comparing Deep Learning Architectures on MNIST: Accuracy vs Energy Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dbb1ec-0436-48eb-9863-2ac35fb2768a",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "This tutorial demonstrates the implementation and comparison of four neural network architectures- Multilayer Perceptron(MLP), Convolutional Neural Network(CNN), Recurrent Neural Network(RNN), and Spiking Neural Network(SNN)-on the MNIST handwritten digital dataset. These models are evaluated on basis of accuracy and computational efficiency( as a proxy for energy usage) while exploring hyper-parameter impacts. This tutorial makes use of the common machine learning libraries such as PyTorch, SNNTorch, Matplotlib and Numpy to provide a clear pipeline for training, visualisation and critical analysis. By the end, the readers will understand trade-offs between the model's complexity, accuracy and efficiency in resource constrained environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75ba861-79b0-490c-88fb-6c900e9e2dde",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "1. Implement MLP, CNN, RNN, and SNN models using Pytorch.\n",
    "2. Train and evaluate models on MNIST\n",
    "3. Analyse hyper-parameter effects on accuracy and training time\n",
    "4. Visualise results with graphs and tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a932000c-9ae1-4df1-96d4-fe1cb8f3b6d3",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Setup: Installing Libraries](#1-setup-installing-libraries)\n",
    "2. [Loading and Preprocessing MNIST Data](#2-loading-and-preprocessing-mnist-data)\n",
    "3. Model Architectures\n",
    "   - [3.1 MLP](#31-mlp)\n",
    "   - [3.2 CNN](#32-cnn)\n",
    "   - [3.3 RNN](#33-rnn)\n",
    "   - [3.4 SNN](#34-snn)\n",
    "4. [Training Loop and Metrics](#4-training-loop-and-metrics)\n",
    "5. [Hyper-parameter Analysis](#5-hyper-parameter-analysis)\n",
    "6. [Results: Accuracy vs. Training Time](#6-results-accuracy-vs-training-time)\n",
    "7. [Conclusion](#7-conclusion)\n",
    "8. [Future Work](#8-future-work)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e6df23-d539-4c8d-9b35-11285cad5931",
   "metadata": {},
   "source": [
    "<h3>Differences from Existing Tutorials</h3>\n",
    "\n",
    "<table style=\"width:100%; text-align: left; border-collapse: collapse; border: 2px solid black;\">\n",
    "    <tr>\n",
    "        <th style=\"border: 2px solid black; padding: 8px;\">Aspect</th>\n",
    "        <th style=\"border: 2px solid black; padding: 8px;\">Existing Tutorials</th>\n",
    "        <th style=\"border: 2px solid black; padding: 8px;\">This Tutorial</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"border: 2px solid black; padding: 8px;\"><b>Models Covered</b></td>\n",
    "        <td style=\"border: 2px solid black; padding: 8px;\">Typically MLP, CNN, or RNN</td>\n",
    "        <td style=\"border: 2px solid black; padding: 8px;\">Adds SNN for bio-inspired efficiency analysis</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"border: 2px solid black; padding: 8px;\"><b>Evaluation Metrics</b></td>\n",
    "        <td style=\"border: 2px solid black; padding: 8px;\">Focus on accuracy</td>\n",
    "        <td style=\"border: 2px solid black; padding: 8px;\">Includes training time as energy efficiency proxy</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"border: 2px solid black; padding: 8px;\"><b>Hyperparameters</b></td>\n",
    "        <td style=\"border: 2px solid black; padding: 8px;\">Limited to learning rate/epochs</td>\n",
    "        <td style=\"border: 2px solid black; padding: 8px;\">Tests optimizer choices and layer configurations</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"border: 2px solid black; padding: 8px;\"><b>Visualization</b></td>\n",
    "        <td style=\"border: 2px solid black; padding: 8px;\">Basic accuracy plots</td>\n",
    "        <td style=\"border: 2px solid black; padding: 8px;\">Comparative tables and multi-model graphs</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498f9b06-c390-4f0b-bf1a-334d9ca46ff6",
   "metadata": {},
   "source": [
    "### 1. Setup: Installing Libraries\n",
    "Install the required libraries if necessary through pip installer using the following command: '**pip install torch torchvision matplotlib numpy snntorch**' and then we can import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be63b2-3ebb-4933-9273-f79cd31e2baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import snntorch as snn  # For SNN\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64772d7-f5c1-49a5-a669-30b73128c796",
   "metadata": {},
   "source": [
    "### 2. Loading and Preprocessing MNIST Data\n",
    "The following code downloads the MNIST data from the MNIST servers and preprocesses it. It is essential to use some part of the data to train the models and the rest to test it, therefore the data is split into train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb58a8-f4e4-4ab1-8d83-e1a737183bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) #The normalization values `mean=0.1307` and `std=0.3081` are precomputed statistics for the MNIST dataset. They are derived from the entire training set and widely adopted in the machine learning community (LeCun et al., 1998; PyTorch Documentation).\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef24b0f1-f6b6-4290-85a5-86ee3f8c069e",
   "metadata": {},
   "source": [
    "### 3. Model Architectures\n",
    "#### 3.1 MLP\n",
    "An MLP is a foundational neural network architecture with fully connected(\"dense\") layers. It processes input data through sequential linear transformations and non-linear activations[[1]](#References). Simple MLP's however, struggle with spatial data like images due to their lack of inductive bias for grid structure.<br>\n",
    "The MLP is structured in the following way:<br>\n",
    "` Flattens the 28×28 MNIST image into a 784-element vector` → `512-neurons hidden layer(ReLU activation)` → `10 neurons (Output)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a456f5e-2266-48c4-a2cd-cc1a345c0d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Flatten(),               # Converts 28x28 image to 1D vector\n",
    "            nn.Linear(28*28, 512),      # Fully connected layer\n",
    "            nn.ReLU(),                  # Non-linear activation\n",
    "            nn.Linear(512, 10)          # Output Layer\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6ceb46-de65-4b9f-b775-1b848d15dc40",
   "metadata": {},
   "source": [
    "#### 3.2 CNN\n",
    "CNNs excel at image tasks by leveraging convolutional layers to detect spatial patterns(edges, textures) hierarchically. They use parameter-sharing(kernels) and pooling to reduce dimensionality while preserving spatial relationships[[2]](#references).<br>\n",
    "The CNN is structured in the following way:<br>\n",
    "`Conv2D (3×3, 32 channels)` → `ReLU` → `MaxPool` → `Conv2D (3×3, 64 channels)` → `ReLU` → `MaxPool` → `Flatten` → `Dense Layer`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74215bd-5483-4898-b9a8-56a8fee39480",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3),  # 1 input channel (grayscale), 32 output channels\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2),      # Reduces feature map size by half   \n",
    "            nn.Conv2d(32, 64, 3), # Deeper feature extraction\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),       \n",
    "            nn.Flatten(),         # Prepare for dense layer\n",
    "            nn.Linear(64*5*5, 10) # Final classification\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b24995-5c84-461a-99e2-792da797462b",
   "metadata": {},
   "source": [
    "#### 3.3 RNN\n",
    "RNNs process sequential data(e.g., time series, text) by maintaining a hidden state that captures temporal dependancies[[3]](#references). Here, we treat each row of the MNIST image as a \"time step\" to demonstrate RNN flexibility.<br>\n",
    "The RNN is implemented using the following structure:<br>\n",
    "`Input image (28×28)` → `Squeeze channel dimension` → `Process 28 rows as a sequence (28 time steps)` → `RNN layer (hidden size 128)` → `Final hidden state` → `Dense layer`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e54975-2198-4d62-bc38-3bd419f65286",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(28, 128, batch_first=True) # Input size 28 (per row), hidden size 128\n",
    "        self.fc = nn.Linear(128, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(1)  # Remove channel dimension\n",
    "        out, _ = self.rnn(x) # Process rows as a sequence\n",
    "        return self.fc(out[:, -1, :]) # Use last time step's output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f858e3-6697-4651-a2eb-e0aad1d1f09e",
   "metadata": {},
   "source": [
    "#### 3.4 SNN\n",
    "SNNs mimic biological neurones by transmitting information via spikes over time. They are highly energy efficient(sparse activations) and suitable neuromorphic hardware[[4]](#references). In the implementation shown below, we make use of 'snntorch' which is a python native library for SNNs.<br>\n",
    "The SNN follows the structure as shown below:<br>\n",
    "`Flattened input` → `Dense layer` → `Leaky integrate-and-fire (LIF) neuron` → `Dense output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae4ceb5-2c80-4984-b443-9f0a8066937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.lif1 = snn.Leaky(beta=0.9) #LIF neuron model\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        mem = self.lif1.init_leaky() # Initialize membrane potential\n",
    "        spk, mem = self.lif1(self.fc1(x), mem) # Update membrane/spike\n",
    "        return self.fc2(spk) # Classify spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b436122c-2340-4aaa-b607-10bf2297ebad",
   "metadata": {},
   "source": [
    "### 4. Training Loop and Metrics\n",
    "The training loop is the core process where the model learns from data. It involves:<br>\n",
    "1. **Forward pass**: which computes predictions.\n",
    "2. **Loss calculation**: Measures error using a loss function.\n",
    "3. **Backward pass**: Computes gradients via backpropagation.\n",
    "4. **Optimisation**: Updates model weights using an optimiser(eg: Adam).<br>\n",
    "\n",
    "In this tutorial we also track training time as a proxy for energy efficiency, since shorter training times often correlate with lower computational and energy costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e839d357-92d7-458c-a4bc-7bf2bc9b2c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, epochs=5):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_time = 0  # Track total training time\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(device), y.to(device)  # Move data to GPU/CPU\n",
    "            optimizer.zero_grad()              # Reset gradients\n",
    "            output = model(X)                  # Forward pass\n",
    "            loss = criterion(output, y)        # Compute loss\n",
    "            loss.backward()                    # Backpropagation\n",
    "            optimizer.step()                   # Update weights\n",
    "        epoch_time = time.time() - start_time\n",
    "        train_time += epoch_time\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Time: {epoch_time:.2f}s\")\n",
    "    \n",
    "    return train_time  # Return total training time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd3fc41-10e4-4c04-a5c5-740ed059c0ef",
   "metadata": {},
   "source": [
    "#### Evaluation Function\n",
    "After training, we evaluate model performance on the test set to measure generalisation accuracy. This ensures the model isn't overfitting to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d686fe-9c4f-457f-b333-1c5dcdb80cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    model.eval()  # Set model to evaluation mode (disables dropout/batchnorm)\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient tracking for efficiency\n",
    "        for X, y in test_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            output = model(X)\n",
    "            pred = output.argmax(dim=1)  # Get predicted class\n",
    "            correct += (pred == y).sum().item()  # Count correct predictions\n",
    "    \n",
    "    return correct / len(test_data)  # Return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62edd8b-fb5c-4892-b6a0-b1e963cd757b",
   "metadata": {},
   "source": [
    "### 5. Hyper-parameter Analysis\n",
    "Hyper-parameters are settings that control the learning process. In this tutorial, we analyse:<br>\n",
    "1. Optimiser Choice(e.g., Adam vs SGD).\n",
    "2. Learning Rate(step size for weight updates).\n",
    "3. Batch Size(number of samples processed per iterations).<br>\n",
    "\n",
    "By default, all models use `Adam` with `lr=0.001` and `batch_size=64`. However you can can use the following code to test different variations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177750bb-d8fd-400b-8426-749e347d5a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Testing different learning rates\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "for lr in learning_rates:\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    train_model(model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4dbb9-2a37-468e-9626-607e516f1040",
   "metadata": {},
   "source": [
    "Use this code with default Adam optimiser with learning rate of 0.001:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d310f59-aaf8-4f32-b30e-e8818f873b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'MLP': MLP(), 'CNN': CNN(), 'RNN': RNN(), 'SNN': SNN()}\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Default: Adam optimizer, lr=0.001\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    train_time = train_model(model, optimizer)\n",
    "    accuracy = test_model(model)\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Training Time (s)': train_time\n",
    "    })\n",
    "    print(f\"{name}: Accuracy={accuracy:.3f}, Time={train_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2618f43-3612-47ee-a8ac-53e21f95bb30",
   "metadata": {},
   "source": [
    "### 6. Results: Accuracy vs. Training Time\n",
    "In order make the results more clear we will be generating graphs that represent the accuracy and training times of the deep learning architectures. The following code generates the graphs and table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b49a2a5-d9bb-4875-827d-d6a379d07085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Generate comparison table\n",
    "df = pd.DataFrame(results)\n",
    "print(\"Performance Comparison:\\n\", df)\n",
    "\n",
    "# Plot results\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "df.plot(x='Model', y='Accuracy', kind='bar', ax=ax[0], title='Accuracy Comparison')\n",
    "df.plot(x='Model', y='Training Time (s)', kind='bar', ax=ax[1], title='Training Time Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dd6869-cb5b-4fc4-8dba-6e67b08f7777",
   "metadata": {},
   "source": [
    "### 7. Conclusion\n",
    "After running all the above cells, we can make the following conclusions:\n",
    "- **MLP**: It has the low training time(i.e. faster training time) but the accuracy is the lowest due to limited spatial processing.\n",
    "- **CNN**: Highest accuracy but it has the slowest training time due to its convolutional operations.\n",
    "- **RNN**: Performs moderately well as it's designed for sequential data.\n",
    "- **SNN**: It might be surprising as by definition this should have the least training time however, it balances out speed with accuracy. In order to achieve better speed or accuracy you could try out hybrid architectures of SNN as mentioned later in the [Future Work](#8-future-work) section.<br>\n",
    "\n",
    "CNN performs the best in terms of accuracy, while MLP's/SNNs are faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6034bc92-f04e-4f17-a526-9c9f1cf2aa2c",
   "metadata": {},
   "source": [
    "### 8. Future Work\n",
    "- Test more hyper-parameters and see how it affects the accuracy and training times(e.g., batch size, layer widths).\n",
    "- Measure actual energy consumption using hardware tools.\n",
    "- Explore hybrid models, like combining CNN-SNN in order to achieve high accuracy with low energy consumption. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc0099f-582c-49ea-8c1c-143b4fbd72e6",
   "metadata": {},
   "source": [
    "### References  \n",
    "1. **MLP**:  \n",
    "   Goodfellow, I., Bengio, Y., & Courville, A. (2016). [*Deep Learning*](https://www.deeplearningbook.org). MIT Press.\n",
    "\n",
    "   PyTorch Linear Layer Documentation: https://pytorch.org/docs/stable/generated/torch.nn.Linear.html  \n",
    "\n",
    "2. **CNN**:  \n",
    "   LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). [Gradient-Based Learning Applied to Document Recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf). *Proceedings of the IEEE*.\n",
    "\n",
    "   PyTorch Conv2d Documentation: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "\n",
    "3. **RNN**:  \n",
    "   Graves, A. (2012). [Supervised Sequence Labelling with Recurrent Neural Networks](https://www.cs.toronto.edu/~graves/preprint.pdf). Springer.\n",
    "\n",
    "   PyTorch RNN Documentation: https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\n",
    "\n",
    "4. **SNN**:  \n",
    "   Eshraghian, J. K., et al. (2021). [Training Spiking Neural Networks Using Lessons from Deep Learning](https://arxiv.org/abs/2109.12894). *arXiv*.\n",
    "\n",
    "5. **PyTorch Documentation**:  \n",
    "   [PyTorch Official Documentation](https://pytorch.org/docs/stable/index.html)  \n",
    "\n",
    "6. **Adam Optimizer**:  \n",
    "   Kingma, D. P., & Ba, J. (2014). [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980). *arXiv*.  \n",
    "\n",
    "7. **MNIST Dataset**:  \n",
    "   LeCun, Y., Cortes, C., & Burges, C. (1998). [The MNIST Database of Handwritten Digits](http://yann.lecun.com/exdb/mnist/).  \n",
    "   [PyTorch MNIST Loading](https://pytorch.org/vision/stable/datasets.html#mnist)  \n",
    "\n",
    "8. **SNNTorch Library**:  \n",
    "   [SNNTorch Documentation](https://snntorch.readthedocs.io/)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44ce069-f28f-4750-9103-933438bde888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
